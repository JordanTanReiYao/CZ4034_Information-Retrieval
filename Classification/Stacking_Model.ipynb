{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Acd49qOj8tJt",
    "outputId": "20d0bf24-d095-4f23-98cf-573dd9fbd623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6SVDg1w8iM7",
    "outputId": "b4f52199-b4c5-4581-fc26-9ae437114132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.68)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maO-ZKHJ3odw"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import contractions\n",
    "import pickle\n",
    "from numpy import *\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6jsxJVQ6uuw"
   },
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 170000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 160\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea8MVWx_6vWU"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text=contractions.fix(text)\n",
    "  text=re.sub(r'\\W+',' ',text)\n",
    "  text=re.sub('\\s\\s+',' ',text)\n",
    "  text=text.strip()\n",
    "  text=text.lower()\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oc45PsVI797E"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('gdrive/My Drive/CZ4034_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnxXIW1z8p2M"
   },
   "outputs": [],
   "source": [
    "with open('gdrive/My Drive/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiIN3eHiTWUD"
   },
   "outputs": [],
   "source": [
    "CNN_LSTM = load_model(\"gdrive/My Drive/CZ4034_CNN_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOmPhfoUTdKP"
   },
   "outputs": [],
   "source": [
    "BI_LSTM = load_model(\"gdrive/My Drive/CZ4034_BI_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VixTXN5yxvCs"
   },
   "outputs": [],
   "source": [
    "LSTM = load_model(\"gdrive/My Drive/CZ4034_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHCx4ZYp2TuV"
   },
   "outputs": [],
   "source": [
    "CNN = load_model(\"gdrive/My Drive/CZ4034_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dc9hET1Syzx"
   },
   "outputs": [],
   "source": [
    "def stacked_dataset(inputX):\n",
    "    stackX = None\n",
    "\n",
    "    # make prediction\n",
    "    yhat1 = BI_LSTM.predict(pad_sequences(tokenizer.texts_to_sequences(inputX.values), maxlen=MAX_SEQUENCE_LENGTH), verbose=0)\n",
    "    # stack predictions into [rows, members, probabilities]\n",
    "    #yhat1=np.array([x for x in np.max(yhat1, axis=1)])\n",
    "    #yhat1=yhat1.reshape()\n",
    "    stackX = yhat1 #\n",
    "    yhat2 = CNN_LSTM.predict(pad_sequences(tokenizer.texts_to_sequences(inputX.values), maxlen=MAX_SEQUENCE_LENGTH), verbose=0)\n",
    "    #yhat2=np.array([x for x in np.max(yhat2, axis=1)])\n",
    "    stackX = dstack((stackX, yhat2))\n",
    "    #x = vec.fit_transform(inputX).toarray()\n",
    "    yhat3 = LSTM.predict(pad_sequences(tokenizer.texts_to_sequences(inputX.values), maxlen=MAX_SEQUENCE_LENGTH), verbose=0)\n",
    "    #yhat2=np.array([x for x in np.max(yhat2, axis=1)])\n",
    "    stackX = dstack((stackX, yhat3))\n",
    "\n",
    "    yhat4 = CNN.predict(pad_sequences(tokenizer.texts_to_sequences(inputX.values), maxlen=MAX_SEQUENCE_LENGTH), verbose=0)\n",
    "    #yhat2=np.array([x for x in np.max(yhat2, axis=1)])\n",
    "    stackX = dstack((stackX, yhat4))\n",
    "\n",
    "    \n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape(stackX.shape[0],stackX.shape[1]*stackX.shape[2])\n",
    "    return stackX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NmL1h3cVv7r"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V9A0zUxTmtX"
   },
   "outputs": [],
   "source": [
    "def fit_stacked_model(inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset( inputX)\n",
    "    # fit the meta learner\n",
    "    model = LogisticRegression() #meta learner\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rooa7fX6VzqW"
   },
   "outputs": [],
   "source": [
    "# make a prediction with the stacked model\n",
    "def stacked_prediction( model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset( inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=fit_stacked_model(train['text'],train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('gdrive/My Drive/Stacked Ensemble Model.pickle','wb') as handle:\n",
    "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqxRUSth-iFf"
   },
   "outputs": [],
   "source": [
    "with open('gdrive/My Drive/Stacked Ensemble Model.pickle','rb') as handle:\n",
    "    model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbxrU_ho8o77"
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('gdrive/My Drive/CZ4034_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGhDYfMo812j"
   },
   "outputs": [],
   "source": [
    "test['text']=test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK6Vp425d2vx",
    "outputId": "992f8050-1bad-4697-aee4-1a2e1d8926ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274.0\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "yhat1 = stacked_prediction(model,test['text'])\n",
    "dur=time()-start\n",
    "print(len(test)//dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwR1-cNm8-vt",
    "outputId": "b83c945b-4ad6-4ad6-fb3a-0495707be12c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.69      0.69       541\n",
      "     neutral       0.81      0.79      0.80       647\n",
      "    positive       0.79      0.81      0.80       769\n",
      "\n",
      "    accuracy                           0.77      1957\n",
      "   macro avg       0.76      0.76      0.76      1957\n",
      "weighted avg       0.77      0.77      0.77      1957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['sentiment'],yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVihmglUdWij",
    "outputId": "1a340841-d498-4531-ce89-6cd66b59d3a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1957, 160)\n"
     ]
    }
   ],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OP84afdx-v8N",
    "outputId": "5dda9827-ffeb-436f-9a7d-15a6692d55b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785.0\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "yhat2 = CNN.predict(X_test)\n",
    "dur=time()-start\n",
    "print(len(test)//dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmNsZyHSdKZL",
    "outputId": "23a0fb05-014a-4e30-a8ce-ccfbc0cc8b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087.0\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "yhat3 = LSTM.predict(X_test)\n",
    "dur=time()-start\n",
    "print(len(test)//dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2pw2IaNdJ_G",
    "outputId": "67840612-f7e5-42ae-f0b6-03e66815e91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.0\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "yhat4 = BI_LSTM.predict(X_test)\n",
    "dur=time()-start\n",
    "print(len(test)//dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwYj-Mozde2U",
    "outputId": "aeb998d9-3082-42c6-cf21-2b758d6c87c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132.0\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "yhat5 = CNN_LSTM.predict(X_test)\n",
    "dur=time()-start\n",
    "print(len(test)//dur)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CZ4034 Stacking Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
